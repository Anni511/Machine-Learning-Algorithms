{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "from sklearn import cross_validation as cv\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def step_gradient(X,m,Y,learning_rate):\n",
    "    new_m = [0 for i in range(len(m))]\n",
    "    N = len(X)\n",
    "    for i in range(X.shape[1]):\n",
    "        x = X[:,i]\n",
    "        new_m[i]= -x*(Y-predict(X,m))\n",
    "    \n",
    "    new_m = np.array(new_m)\n",
    "    \n",
    "    for i in range(X.shape[1]):\n",
    "        m[i] -= (learning_rate*np.mean(new_m[i])) \n",
    "\n",
    "    return m\n",
    "\n",
    "# Returns a list of values of sigmoid fn\n",
    "def sigmoid(z):\n",
    "    return 1.0/(1+np.exp(-z))\n",
    "\n",
    "# Returns Probablility \n",
    "def predict(X,m):\n",
    "    z = np.dot(X,m)\n",
    "    return sigmoid(z)\n",
    "\n",
    "def decision_boundary(prob):\n",
    "    for i in range(len(prob)):\n",
    "        if prob[i]<0.5:\n",
    "            prob[i]=0\n",
    "        else:\n",
    "            prob[i]=1\n",
    "    return prob\n",
    "\n",
    "def classify(X,final_m):\n",
    "    prediction = predict(X,final_m)\n",
    "    final_pred = decision_boundary(prediction)\n",
    "    return final_pred\n",
    "        \n",
    "        \n",
    "def cost(X,m,Y):\n",
    "    N = len(Y)\n",
    "    prediction = predict(X,m)\n",
    "    c1 = -Y*np.log(prediction)\n",
    "    c2 = (1-Y)*np.log(1-prediction)\n",
    "    total_cost = c1-c2\n",
    "    total_cost = total_cost.sum()/N\n",
    "    return total_cost\n",
    "\n",
    "def normalize(X):\n",
    "    if(len(X.shape)==1):\n",
    "        x = X\n",
    "        x_mean = np.mean(x)\n",
    "        x_range = np.amax(x) - np.amin(x)\n",
    "        x = (x-x_mean)\n",
    "        x = x/x_range\n",
    "        X = x\n",
    "    else:\n",
    "        for i in range(X.shape[1]):\n",
    "            x = X[:][i]\n",
    "            x_mean = np.mean(x)\n",
    "            x_range = np.amax(x) - np.amin(x)\n",
    "            x = (x-x_mean)\n",
    "            x = x/x_range\n",
    "            X[:][i] = x\n",
    "    return X\n",
    "        \n",
    "def gd_runner(X, num_iterations, learning_rate, Y):\n",
    "    m = np.zeros((X.shape[1],))\n",
    "    print(\"Start : \", cost(X,m,Y))\n",
    "    for i in range(num_iterations):\n",
    "        m = step_gradient(X,m,Y,learning_rate)\n",
    "    \n",
    "    print(\"FINAL COST : \", cost(X,m,Y))\n",
    "    return m\n",
    "\n",
    "def accuracy(predicted_labels, actual_labels):\n",
    "    diff = predicted_labels - actual_labels\n",
    "    return 1.0 - (float(np.count_nonzero(diff)) / len(diff))\n",
    "\n",
    "def runiris():\n",
    "    iris = datasets.load_iris()\n",
    "    X = iris.data[:100]\n",
    "    Y = iris.target[:100]\n",
    "    Dummy = np.ones(shape=(len(X),1))\n",
    "    X = np.append(Dummy, X, axis=1)\n",
    "    num_iterations = 100000\n",
    "    learning_rate = 0.0001\n",
    "\n",
    "    final_m = gd_runner(X, num_iterations, learning_rate, Y)\n",
    "    final_prediction = predict(X,final_m)\n",
    "    print(\"Final Prediction Matrix: \", final_prediction)\n",
    "    final_classification = classify(X,final_m)\n",
    "    print(\"Final Classification Matrix: \", final_classification)\n",
    "    print(\"Accuracy of The Trained Model: \", accuracy(final_classification,Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start :  0.69314718056\n",
      "FINAL COST :  0.067513612603\n",
      "Final Prediction Matrix:  [ 0.05217502  0.08934121  0.06701722  0.10144837  0.04854417  0.05817004\n",
      "  0.07010707  0.0686772   0.1114558   0.08827324  0.04595083  0.08387968\n",
      "  0.08610271  0.06296406  0.01910389  0.0238865   0.0315612   0.05568259\n",
      "  0.05552105  0.0481665   0.08311669  0.05674855  0.02926605  0.11865064\n",
      "  0.1288363   0.11605266  0.09031288  0.05907588  0.05606143  0.10396174\n",
      "  0.11125286  0.07025077  0.03040341  0.02314566  0.08827324  0.05324377\n",
      "  0.04021037  0.08827324  0.08786116  0.0668891   0.0491574   0.1722455\n",
      "  0.07252469  0.09308543  0.09315958  0.09755998  0.05251701  0.07978204\n",
      "  0.04720752  0.06520678  0.95143208  0.94754511  0.97057315  0.95891722\n",
      "  0.96900539  0.96680134  0.96107405  0.86883147  0.95978088  0.93860405\n",
      "  0.93079898  0.94072401  0.94817458  0.97187194  0.86495851  0.93611647\n",
      "  0.9654044   0.93097863  0.98189051  0.93188701  0.97636732  0.92122857\n",
      "  0.98649755  0.97094745  0.93988422  0.94359984  0.97362061  0.98118669\n",
      "  0.9651044   0.85513015  0.93013531  0.91373942  0.91831809  0.98960628\n",
      "  0.96724573  0.9462104   0.96205473  0.97243144  0.92770611  0.94987026\n",
      "  0.96795331  0.96367956  0.93606329  0.87724752  0.95367133  0.93180361\n",
      "  0.94201048  0.94300365  0.78903348  0.93889906]\n",
      "Final Classification Matrix:  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      "Accuracy of The Trained Model:  1.0\n"
     ]
    }
   ],
   "source": [
    "runiris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Testing on Different Testing and Training Data\n",
    "def runiris_testtrain():\n",
    "    iris = datasets.load_iris()\n",
    "    X = iris.data[:100]\n",
    "    Y = iris.target[:100]\n",
    "    X_train, X_test, Y_train, Y_test = [],[],[],[]\n",
    "    Dummy = np.ones(shape=(len(X),1))\n",
    "    X = np.append(Dummy, X, axis=1)\n",
    "    for i in range(100):\n",
    "        if(i%5==0):\n",
    "            X_test.append(X[i])\n",
    "            Y_test.append(Y[i])\n",
    "        else:    \n",
    "            X_train.append(X[i])\n",
    "            Y_train.append(Y[i])\n",
    "    X_test = np.array(X_test)\n",
    "    X_train = np.array(X_train)\n",
    "    Y_train = np.array(Y_train)\n",
    "    Y_test = np.array(Y_test)\n",
    "    num_iterations = 100000\n",
    "    learning_rate = 0.0001\n",
    "    final_m = gd_runner(X_train, num_iterations, learning_rate, Y_train)\n",
    "    final_prediction = predict(X_test,final_m)\n",
    "    print(\"Final Prediction Matrix: \", final_prediction)\n",
    "    final_classification = classify(X_test,final_m)\n",
    "    print(\"Final Classification Matrix: \", final_classification)\n",
    "    print(\"Accuracy of The Trained Model: \", accuracy(final_classification,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start :  0.69314718056\n",
      "FINAL COST :  0.0687069813637\n",
      "Final Prediction Matrix:  [ 0.05245733  0.05825598  0.0462166   0.023883    0.08380022  0.11710397\n",
      "  0.11183764  0.05377409  0.04940151  0.09836831  0.95192918  0.96680861\n",
      "  0.93146968  0.93674689  0.97625124  0.94416676  0.93072025  0.9459878\n",
      "  0.9679899   0.93177661]\n",
      "Final Classification Matrix:  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.]\n",
      "Accuracy of The Trained Model:  1.0\n"
     ]
    }
   ],
   "source": [
    "runiris_testtrain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass Logistic Regression Using Binary Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_gradient(X,m,Y,learning_rate):\n",
    "    new_m = [0 for i in range(len(m))]\n",
    "    N = len(X)\n",
    "    for i in range(X.shape[1]):\n",
    "        x = X[:,i]\n",
    "        new_m[i]= -x*(Y-predict(X,m))\n",
    "    \n",
    "    new_m = np.array(new_m)\n",
    "    \n",
    "    for i in range(X.shape[1]):\n",
    "        m[i] -= (learning_rate*np.mean(new_m[i])) \n",
    "\n",
    "    return m\n",
    "\n",
    "# Returns a list of values of sigmoid fn\n",
    "def sigmoid(z):\n",
    "    return 1.0/(1+np.exp(-z))\n",
    "\n",
    "# Returns Probablility \n",
    "def predict(X,m):\n",
    "    z = np.dot(X,m)\n",
    "    return sigmoid(z)\n",
    "\n",
    "def decision_boundary(prob):\n",
    "    for i in range(len(prob)):\n",
    "        if prob[i]<0.5:\n",
    "            prob[i]=0\n",
    "        else:\n",
    "            prob[i]=1\n",
    "    return prob\n",
    "\n",
    "def classify(X,final_m):\n",
    "    prediction = predict(X,final_m)\n",
    "    final_pred = decision_boundary(prediction)\n",
    "    return final_pred\n",
    "        \n",
    "def cost(X,m,Y):\n",
    "    N = len(Y)\n",
    "    prediction = predict(X,m)\n",
    "    c1 = -Y*np.log(prediction)\n",
    "    c2 = (1-Y)*np.log(1-prediction)\n",
    "    total_cost = c1-c2\n",
    "    total_cost = total_cost.sum()/N\n",
    "    return total_cost\n",
    "\n",
    "def normalize(X):\n",
    "    if(len(X.shape)==1):\n",
    "        x = X\n",
    "        x_mean = np.mean(x)\n",
    "        x_range = np.amax(x) - np.amin(x)\n",
    "        x = (x-x_mean)\n",
    "        x = x/x_range\n",
    "        X = x\n",
    "    else:\n",
    "        for i in range(X.shape[1]):\n",
    "            x = X[:][i]\n",
    "            x_mean = np.mean(x)\n",
    "            x_range = np.amax(x) - np.amin(x)\n",
    "            x = (x-x_mean)\n",
    "            x = x/x_range\n",
    "            X[:][i] = x\n",
    "    return X\n",
    "        \n",
    "def gd_runner(X, num_iterations, learning_rate, Y):\n",
    "    m = np.zeros((X.shape[1],))\n",
    "    print(\"Start : \", cost(X,m,Y))\n",
    "    for i in range(num_iterations):\n",
    "        m = step_gradient(X,m,Y,learning_rate)\n",
    "    \n",
    "    print(\"FINAL COST : \", cost(X,m,Y))\n",
    "    return m\n",
    "\n",
    "def accuracy(predicted_labels, actual_labels):\n",
    "    count_mismatch = 0\n",
    "    for i in range(len(predicted_labels)):\n",
    "        if(predicted_labels[i] != actual_labels[i]):\n",
    "            count_mismatch += 1\n",
    "    return 1.0 - (float(count_mismatch) / len(actual_labels))\n",
    "\n",
    "def split_target(Y):\n",
    "    Y0,Y1,Y2 = [],[],[]\n",
    "    for i in range(len(Y)):\n",
    "        if(Y[i]==0):\n",
    "            Y0.append(1)\n",
    "            Y1.append(0)\n",
    "            Y2.append(0)\n",
    "        if(Y[i]==1):\n",
    "            Y0.append(0)\n",
    "            Y1.append(1)\n",
    "            Y2.append(0)\n",
    "        if(Y[i]==2):\n",
    "            Y0.append(0)\n",
    "            Y1.append(0)\n",
    "            Y2.append(1)    \n",
    "    return np.array(Y0),np.array(Y1),np.array(Y2)\n",
    "\n",
    "def run_multiLR(X_train,X_test,num_iterations,learning_rate,Y0,Y1,Y2,Y_test):\n",
    "    Y = [Y0,Y1,Y2]\n",
    "    Classification_Binary = []\n",
    "    Final_Classification = []\n",
    "    Final_Prediction = []\n",
    "    for y in Y:\n",
    "        final_m = gd_runner(X_train, num_iterations, learning_rate, y)\n",
    "        final_prediction = predict(X_test,final_m)\n",
    "        Final_Prediction.append(final_prediction)\n",
    "    for i in range(len(Final_Prediction[0])):\n",
    "        if((Final_Prediction[0][i]>Final_Prediction[1][i]) and (Final_Prediction[0][i]>Final_Prediction[2][i])):\n",
    "            Final_Classification.append(0)\n",
    "        elif((Final_Prediction[1][i]>Final_Prediction[0][i]) and (Final_Prediction[1][i]>Final_Prediction[2][i])):\n",
    "            Final_Classification.append(1)\n",
    "        else:\n",
    "            Final_Classification.append(2)\n",
    "    print(Final_Classification)  \n",
    "    print(\"Accuracy of The Trained Model: \", accuracy(Final_Classification,Y_test))\n",
    "\n",
    "def runiris():\n",
    "    iris = datasets.load_iris()\n",
    "    X = iris.data\n",
    "    Y = iris.target\n",
    "    Dummy = np.ones(shape=(len(X),1))\n",
    "    X = np.append(Dummy, X, axis=1)\n",
    "    normalize(X)\n",
    "    num_iterations = 100000\n",
    "    learning_rate = 0.001\n",
    "    Y0, Y1, Y2 = split_target(Y)\n",
    "   \n",
    "    run_multiLR(X,X,num_iterations,learning_rate,Y0,Y1,Y2,Y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start :  0.69314718056\n",
      "FINAL COST :  0.011081618688\n",
      "Start :  0.69314718056\n",
      "FINAL COST :  0.533064099229\n",
      "Start :  0.69314718056\n",
      "FINAL COST :  0.126678159574\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "Accuracy of The Trained Model:  0.9733333333333334\n"
     ]
    }
   ],
   "source": [
    "runiris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Testing on Different Testing and Training Data\n",
    "def runiris_testtrain():\n",
    "    iris = datasets.load_iris()\n",
    "    X = iris.data\n",
    "    Y = iris.target\n",
    "    X_train, X_test, Y_train, Y_test = [],[],[],[]\n",
    "    Dummy = np.ones(shape=(len(X),1))\n",
    "    X = np.append(Dummy, X, axis=1)\n",
    "    normalize(X)\n",
    "    for i in range(150):\n",
    "        if(i%5==0):\n",
    "            X_test.append(X[i])\n",
    "            Y_test.append(Y[i])\n",
    "        else:    \n",
    "            X_train.append(X[i])\n",
    "            Y_train.append(Y[i])\n",
    "    X_test = np.array(X_test)\n",
    "    X_train = np.array(X_train)\n",
    "    Y_train = np.array(Y_train)\n",
    "    Y_test = np.array(Y_test)\n",
    "    num_iterations = 100000\n",
    "    learning_rate = 0.0001\n",
    "    \n",
    "    Y0, Y1, Y2 = split_target(Y_train)\n",
    "   \n",
    "    run_multiLR(X_train,X_test,num_iterations,learning_rate,Y0,Y1,Y2,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start :  0.69314718056\n",
      "FINAL COST :  0.0688280204607\n",
      "Start :  0.69314718056\n",
      "FINAL COST :  0.586002677297\n",
      "Start :  0.69314718056\n",
      "FINAL COST :  0.296537722815\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 1, 1, 2, 1, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "Accuracy of The Trained Model:  0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "runiris_testtrain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
